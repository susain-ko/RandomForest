{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.tree import export_graphviz\n",
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "from datetime import datetime, timedelta\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('market_value_of_assets', 0.014749970894138835),\n",
       "             ('profitability', 0.0084570677654764864),\n",
       "             ('industry', 0.0056706321485244472),\n",
       "             ('tobinq', 0.0051939753614112976),\n",
       "             ('leverage', 0.004872540821724558),\n",
       "             ('total_assets', 0.0016239030556651367),\n",
       "             ('ppe', 0.0016109977754307501),\n",
       "             ('pct_of_stocks', 0.00014295432251064478),\n",
       "             ('pct_of_cash', 9.9452122296868903e-05)])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.read_csv(\"X.csv\")\n",
    "Y = pd.read_csv(\"Y.csv\", header=None)\n",
    "Y = Y.values.flatten()\n",
    "n = X.shape[0]\n",
    "feature_list = ['total_assets', 'market_value_of_assets', 'tobinq', 'ppe', 'profitability', 'leverage', 'industry', 'pct_of_cash', 'pct_of_stocks']\n",
    "time_dep_feature_list = ['total_assets', 'market_value_of_assets', 'tobinq', 'ppe', 'profitability', 'leverage'] # This keeps time-dependent features\n",
    "special_feature_list = ['industry'] # This one keeps only categorical or time-independent features from Compustat\n",
    "deal_feature_list = ['pct_of_cash', 'pct_of_stocks']\n",
    "\n",
    "################################################\n",
    "#### Default Run of Random Forest Algorithm ####\n",
    "################################################\n",
    "regr = RandomForestRegressor(random_state=0)\n",
    "regr.fit(X, Y)   \n",
    "\n",
    "\n",
    "# In[17]:\n",
    "\n",
    "# This is our score vector for each feature\n",
    "score_vec = regr.feature_importances_\n",
    "\n",
    "# Get the name of n features with largest scores\n",
    "def get_max_score_features(score_vec, column_names, n):\n",
    "    \"\"\"\n",
    "    output: a dictionary with key being feature names and value being corresponding feature scores\n",
    "    \"\"\"\n",
    "    max_ind = np.argsort(-score_vec)[0:n]\n",
    "    out = OrderedDict()\n",
    "    for ind in max_ind:\n",
    "        out[column_names[ind]] = score_vec[ind]\n",
    "    return out\n",
    "\n",
    "score_dict = get_max_score_features(score_vec, X.columns, len(score_vec))\n",
    "score_dict\n",
    "\n",
    "\n",
    "# In[18]:\n",
    "\n",
    "#####################################\n",
    "#### Output Analysis Begins Here ####\n",
    "#####################################\n",
    "\n",
    "### Graph the Distribution of Scores ###\n",
    "plt.hist(score_vec, bins = 'auto')\n",
    "plt.xlabel('Score')\n",
    "plt.title('Distribution of Feature Scores')\n",
    "plt.show()\n",
    "# Graph is highly skewed to the right\n",
    "\n",
    "### Calculate Mean Score of Each Year Period Prior to Deal ###\n",
    "# Recall that 3 refers to the year period 3 years prior to the deal,\n",
    "# 2 refers to the year period 2 years prior to the deal, and 1 to just\n",
    "# the year preceding the deal.\n",
    "\n",
    "def period_mean_score(score_dict, num_yrs):\n",
    "    out = OrderedDict()\n",
    "    for i in range(num_yrs):\n",
    "        search_string = '_' + str(i+1) + '_'\n",
    "        out[i + 1] = np.mean([value for key, value in score_dict.items() if search_string in key.lower()])\n",
    "    return out\n",
    "\n",
    "### Calculate Mean Score of Each Feature ###\n",
    "def feature_mean_score(score_dict, feature_list):\n",
    "    feature_mean_score = {}\n",
    "    for feature in feature_list:\n",
    "        one_score = np.mean([value for key, value in score_dict.items() if feature in key.lower()])\n",
    "        feature_mean_score[feature] = one_score\n",
    "    out = OrderedDict(sorted(feature_mean_score.items(), key=itemgetter(1), reverse = True))\n",
    "    return out\n",
    "\n",
    "# Observe that market value of assets has a notably high score\n",
    "feature_mean_score(score_dict, feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['acq_total_assets_3_Q1',\n",
       " 'acq_total_assets_3_Q2',\n",
       " 'acq_total_assets_3_Q3',\n",
       " 'acq_total_assets_3_Q4',\n",
       " 'acq_total_assets_2_Q1',\n",
       " 'acq_total_assets_2_Q2',\n",
       " 'acq_total_assets_2_Q3',\n",
       " 'acq_total_assets_2_Q4',\n",
       " 'acq_total_assets_1_Q1',\n",
       " 'acq_total_assets_1_Q2',\n",
       " 'acq_total_assets_1_Q3',\n",
       " 'acq_total_assets_1_Q4',\n",
       " 'acq_market_value_of_assets_3_Q1',\n",
       " 'acq_market_value_of_assets_3_Q2',\n",
       " 'acq_market_value_of_assets_3_Q3',\n",
       " 'acq_market_value_of_assets_3_Q4',\n",
       " 'acq_market_value_of_assets_2_Q1',\n",
       " 'acq_market_value_of_assets_2_Q2',\n",
       " 'acq_market_value_of_assets_2_Q3',\n",
       " 'acq_market_value_of_assets_2_Q4',\n",
       " 'acq_market_value_of_assets_1_Q1',\n",
       " 'acq_market_value_of_assets_1_Q2',\n",
       " 'acq_market_value_of_assets_1_Q3',\n",
       " 'acq_market_value_of_assets_1_Q4',\n",
       " 'acq_tobinq_3_Q1',\n",
       " 'acq_tobinq_3_Q2',\n",
       " 'acq_tobinq_3_Q3',\n",
       " 'acq_tobinq_3_Q4',\n",
       " 'acq_tobinq_2_Q1',\n",
       " 'acq_tobinq_2_Q2',\n",
       " 'acq_tobinq_2_Q3',\n",
       " 'acq_tobinq_2_Q4',\n",
       " 'acq_tobinq_1_Q1',\n",
       " 'acq_tobinq_1_Q2',\n",
       " 'acq_tobinq_1_Q3',\n",
       " 'acq_tobinq_1_Q4',\n",
       " 'acq_ppe_3_Q1',\n",
       " 'acq_ppe_3_Q2',\n",
       " 'acq_ppe_3_Q3',\n",
       " 'acq_ppe_3_Q4',\n",
       " 'acq_ppe_2_Q1',\n",
       " 'acq_ppe_2_Q2',\n",
       " 'acq_ppe_2_Q3',\n",
       " 'acq_ppe_2_Q4',\n",
       " 'acq_ppe_1_Q1',\n",
       " 'acq_ppe_1_Q2',\n",
       " 'acq_ppe_1_Q3',\n",
       " 'acq_ppe_1_Q4',\n",
       " 'acq_profitability_3_Q1',\n",
       " 'acq_profitability_3_Q2',\n",
       " 'acq_profitability_3_Q3',\n",
       " 'acq_profitability_3_Q4',\n",
       " 'acq_profitability_2_Q1',\n",
       " 'acq_profitability_2_Q2',\n",
       " 'acq_profitability_2_Q3',\n",
       " 'acq_profitability_2_Q4',\n",
       " 'acq_profitability_1_Q1',\n",
       " 'acq_profitability_1_Q2',\n",
       " 'acq_profitability_1_Q3',\n",
       " 'acq_profitability_1_Q4',\n",
       " 'acq_leverage_3_Q1',\n",
       " 'acq_leverage_3_Q2',\n",
       " 'acq_leverage_3_Q3',\n",
       " 'acq_leverage_3_Q4',\n",
       " 'acq_leverage_2_Q1',\n",
       " 'acq_leverage_2_Q2',\n",
       " 'acq_leverage_2_Q3',\n",
       " 'acq_leverage_2_Q4',\n",
       " 'acq_leverage_1_Q1',\n",
       " 'acq_leverage_1_Q2',\n",
       " 'acq_leverage_1_Q3',\n",
       " 'acq_leverage_1_Q4',\n",
       " 'tar_total_assets_3_Q1',\n",
       " 'tar_total_assets_3_Q2',\n",
       " 'tar_total_assets_3_Q3',\n",
       " 'tar_total_assets_3_Q4',\n",
       " 'tar_total_assets_2_Q1',\n",
       " 'tar_total_assets_2_Q2',\n",
       " 'tar_total_assets_2_Q3',\n",
       " 'tar_total_assets_2_Q4',\n",
       " 'tar_total_assets_1_Q1',\n",
       " 'tar_total_assets_1_Q2',\n",
       " 'tar_total_assets_1_Q3',\n",
       " 'tar_total_assets_1_Q4',\n",
       " 'tar_market_value_of_assets_3_Q1',\n",
       " 'tar_market_value_of_assets_3_Q2',\n",
       " 'tar_market_value_of_assets_3_Q3',\n",
       " 'tar_market_value_of_assets_3_Q4',\n",
       " 'tar_market_value_of_assets_2_Q1',\n",
       " 'tar_market_value_of_assets_2_Q2',\n",
       " 'tar_market_value_of_assets_2_Q3',\n",
       " 'tar_market_value_of_assets_2_Q4',\n",
       " 'tar_market_value_of_assets_1_Q1',\n",
       " 'tar_market_value_of_assets_1_Q2',\n",
       " 'tar_market_value_of_assets_1_Q3',\n",
       " 'tar_market_value_of_assets_1_Q4',\n",
       " 'tar_tobinq_3_Q1',\n",
       " 'tar_tobinq_3_Q2',\n",
       " 'tar_tobinq_3_Q3',\n",
       " 'tar_tobinq_3_Q4',\n",
       " 'tar_tobinq_2_Q1',\n",
       " 'tar_tobinq_2_Q2',\n",
       " 'tar_tobinq_2_Q3',\n",
       " 'tar_tobinq_2_Q4',\n",
       " 'tar_tobinq_1_Q1',\n",
       " 'tar_tobinq_1_Q2',\n",
       " 'tar_tobinq_1_Q3',\n",
       " 'tar_tobinq_1_Q4',\n",
       " 'tar_ppe_3_Q1',\n",
       " 'tar_ppe_3_Q2',\n",
       " 'tar_ppe_3_Q3',\n",
       " 'tar_ppe_3_Q4',\n",
       " 'tar_ppe_2_Q1',\n",
       " 'tar_ppe_2_Q2',\n",
       " 'tar_ppe_2_Q3',\n",
       " 'tar_ppe_2_Q4',\n",
       " 'tar_ppe_1_Q1',\n",
       " 'tar_ppe_1_Q2',\n",
       " 'tar_ppe_1_Q3',\n",
       " 'tar_ppe_1_Q4',\n",
       " 'tar_profitability_3_Q1',\n",
       " 'tar_profitability_3_Q2',\n",
       " 'tar_profitability_3_Q3',\n",
       " 'tar_profitability_3_Q4',\n",
       " 'tar_profitability_2_Q1',\n",
       " 'tar_profitability_2_Q2',\n",
       " 'tar_profitability_2_Q3',\n",
       " 'tar_profitability_2_Q4',\n",
       " 'tar_profitability_1_Q1',\n",
       " 'tar_profitability_1_Q2',\n",
       " 'tar_profitability_1_Q3',\n",
       " 'tar_profitability_1_Q4',\n",
       " 'tar_leverage_3_Q1',\n",
       " 'tar_leverage_3_Q2',\n",
       " 'tar_leverage_3_Q3',\n",
       " 'tar_leverage_3_Q4',\n",
       " 'tar_leverage_2_Q1',\n",
       " 'tar_leverage_2_Q2',\n",
       " 'tar_leverage_2_Q3',\n",
       " 'tar_leverage_2_Q4',\n",
       " 'tar_leverage_1_Q1',\n",
       " 'tar_leverage_1_Q2',\n",
       " 'tar_leverage_1_Q3',\n",
       " 'tar_leverage_1_Q4',\n",
       " 'pct_of_cash',\n",
       " 'pct_of_stocks',\n",
       " 'acq_industry_0',\n",
       " 'acq_industry_1',\n",
       " 'acq_industry_2',\n",
       " 'acq_industry_3',\n",
       " 'acq_industry_4',\n",
       " 'acq_industry_5',\n",
       " 'acq_industry_6',\n",
       " 'acq_industry_7',\n",
       " 'acq_industry_8',\n",
       " 'acq_industry_10',\n",
       " 'tar_industry_0',\n",
       " 'tar_industry_1',\n",
       " 'tar_industry_2',\n",
       " 'tar_industry_3',\n",
       " 'tar_industry_4',\n",
       " 'tar_industry_5',\n",
       " 'tar_industry_6',\n",
       " 'tar_industry_7',\n",
       " 'tar_industry_8',\n",
       " 'tar_industry_10']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X, Y)\n",
    "\n",
    "# Make predictions\n",
    "Y_pred = regr.predict(X)\n",
    "\n",
    "# Compute some statistics\n",
    "res = Y - Y_pred\n",
    "#standardized residuals\n",
    "sig_hat = sqrt(sum(res**2)/(n-p-1))\n",
    "h = X.dot(inv(X.transpose().dot(X))).dot(X.transpose())\n",
    "h_diag = np.diag(h)\n",
    "std_res = res/(sig_hat*np.sqrt(np.ones(len(h_diag))-h_diag))\n",
    "\n",
    "# #predicted residuals\n",
    "# pred_res = res/(1-h_diag)\n",
    "# #RSS[i]\n",
    "# RSS = sum(res^2)\n",
    "# RSS_i = RSS - pred_res*res\n",
    "# #standardized predicted residuals\n",
    "# std_pred_res = (pred_res*sqrt(1 - h_diag))/sqrt(RSS_i/(n-p-2))\n",
    "# #Cook's distance\n",
    "# cook = std_res^2/(p+1)*h_diag/(1-h_diag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "drop() got an unexpected keyword argument 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-85-57013eb6c466>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acq_industry_0'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'tar_industry_0'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: drop() got an unexpected keyword argument 'columns'"
     ]
    }
   ],
   "source": [
    "X.drop(columns=['acq_industry_0', 'tar_industry_0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
